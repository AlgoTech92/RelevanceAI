:py:mod:`relevanceai.vector_tools.cluster`
==========================================

.. py:module:: relevanceai.vector_tools.cluster


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   relevanceai.vector_tools.cluster.ClusterBase
   relevanceai.vector_tools.cluster.CentroidCluster
   relevanceai.vector_tools.cluster.DensityCluster
   relevanceai.vector_tools.cluster.MiniBatchKMeans
   relevanceai.vector_tools.cluster.KMeans
   relevanceai.vector_tools.cluster.HDBSCAN
   relevanceai.vector_tools.cluster.Cluster




.. py:class:: ClusterBase

   Bases: :py:obj:`relevanceai.logger.LoguruLogger`, :py:obj:`doc_utils.DocUtils`

   Using verbose loguru as base logger for now

   .. py:method:: __call__(self, *args, **kwargs)


   .. py:method:: fit_transform(self, vectors)
      :abstractmethod:

      


   .. py:method:: fit_documents(self, vector_field: list, docs: list, alias: str = 'default', cluster_field: str = '_cluster_', return_only_clusters: bool = True)

      Train clustering algorithm on documents and then store the labels
      inside the documents.

      :param vector_field: The vector field of the documents
      :type vector_field: list
      :param docs: List of documents to run clustering on
      :type docs: list
      :param alias: What the clusters can be called
      :type alias: str
      :param cluster_field: What the cluster fields should be called
      :type cluster_field: str
      :param return_only_clusters: If True, return only clusters, otherwise returns the original document
      :type return_only_clusters: bool


   .. py:method:: to_metadata(self)
      :abstractmethod:

      You can also store the metadata of this clustering algorithm



   .. py:method:: _label_cluster(self, label: Union[int, str])


   .. py:method:: _label_clusters(self, labels)



.. py:class:: CentroidCluster

   Bases: :py:obj:`ClusterBase`

   Using verbose loguru as base logger for now

   .. py:method:: __call__(self, *args, **kwargs)


   .. py:method:: fit_transform(self, vectors)
      :abstractmethod:

      


   .. py:method:: get_centers(self) -> Union[numpy.ndarray, List[list]]
      :abstractmethod:

      Get centers for the centroid-based clusters



   .. py:method:: get_centroid_docs(self) -> List

      Get the centroid documents to store.




.. py:class:: DensityCluster

   Bases: :py:obj:`ClusterBase`

   Using verbose loguru as base logger for now

   .. py:method:: __call__(self, *args, **kwargs)


   .. py:method:: fit_transform(self, vectors)
      :abstractmethod:

      



.. py:class:: MiniBatchKMeans(k: Union[None, int] = 10, init: str = 'k-means++', verbose: bool = True, compute_labels: bool = True, max_no_improvement: int = 2)

   Bases: :py:obj:`CentroidCluster`

   Using verbose loguru as base logger for now

   .. py:method:: _init_model(self)


   .. py:method:: fit_transform(self, vectors: Union[numpy.ndarray, List])

      Fit and transform transform the vectors


   .. py:method:: get_centers(self)

      Returns centroids of clusters



   .. py:method:: to_metadata(self)

      Editing the metadata of the function




.. py:class:: KMeans(k=10, init='k-means++', n_init=10, max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='auto')

   Bases: :py:obj:`MiniBatchKMeans`

   Using verbose loguru as base logger for now

   .. py:method:: _init_model(self)


   .. py:method:: to_metadata(self)

      Editing the metadata of the function




.. py:class:: HDBSCAN

   Bases: :py:obj:`DensityCluster`

   Using verbose loguru as base logger for now

   .. py:method:: fit_transform(self, vectors: numpy.ndarray, cluster_args: Optional[Dict[Any, Any]] = CLUSTER_DEFAULT_ARGS['hdbscan'], min_cluster_size: Union[None, int] = 10) -> numpy.ndarray

      



.. py:class:: Cluster(project, api_key)

   Bases: :py:obj:`relevanceai.api.client.BatchAPIClient`, :py:obj:`ClusterBase`

   Batch API client

   .. py:method:: _choose_k(vectors: numpy.ndarray)
      :staticmethod:

      "
      Choose k clusters


   .. py:method:: cluster(vectors: numpy.ndarray, cluster: Union[relevanceai.vector_tools.constants.CLUSTER, ClusterBase], cluster_args: Union[None, dict], k: Union[None, int] = None) -> numpy.ndarray
      :staticmethod:

      Cluster vectors


   .. py:method:: kmeans_cluster(self, dataset_id: str, vector_fields: list, filters: List = [], k: Union[None, int] = 10, init: str = 'k-means++', n_init: int = 10, max_iter: int = 300, tol: float = 0.0001, verbose: bool = True, random_state: Optional[int] = None, copy_x: bool = True, algorithm: str = 'auto', alias: str = 'default', cluster_field: str = '_cluster_', update_documents_chunksize: int = 50, overwrite: bool = False)

      This function performs all the steps required for Kmeans clustering:
      1- Loads the data
      2- Clusters the data
      3- Updates the data with clustering info
      4- Adds the centroid to the hidden centroid collection

      :param dataset_id: name of the dataser
      :type dataset_id: string
      :param vector_fields: a list containing the vector field to be used for clustering
      :type vector_fields: list
      :param filters: a list to filter documents of the dataset,
      :type filters: list
      :param k: K in Kmeans
      :type k: int
      :param init: "k-means++" -> Kmeans algorithm parameter
      :type init: string
      :param n_init: number of reinitialization for the kmeans algorithm
      :type n_init: int
      :param max_iter: max iteration in the kmeans algorithm
      :type max_iter: int
      :param tol: tol in the kmeans algorithm
      :type tol: int
      :param verbose: True by default
      :type verbose: bool
      :param random_state = None: None by default -> Kmeans algorithm parameter
      :param copy_x: True bydefault
      :type copy_x: bool
      :param algorithm: "auto" by default
      :type algorithm: string
      :param alias: "default", string to be used in naming of the field showing the clustering results
      :type alias: string
      :param cluster_field: "_cluster_", string to name the main cluster field
      :type cluster_field: string
      :param overwrite: False by default, To overwite an existing clusering result
      :type overwrite: bool

      .. rubric:: Example

      >>> client.vector_tools.cluster.kmeans_cluster(
          dataset_id="sample_dataset",
          vector_fields=["sample_1_vector_"] # Only 1 vector field is supported for now
      )



